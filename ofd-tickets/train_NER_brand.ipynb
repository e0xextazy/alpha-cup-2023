{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213f2d9a-3250-4c88-a659-b9ca5e17b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OUTPUT_DIR = './labse_v4_brand'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b71e000a-7f00-4616-b32c-a20739ee02dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    apex=True\n",
    "    print_freq=100\n",
    "    num_workers=10\n",
    "    model=\"sentence-transformers/LaBSE\"\n",
    "    scheduler='linear' # ['linear', 'cosine']\n",
    "    batch_scheduler=True\n",
    "    num_cycles=0.5\n",
    "    num_warmup_steps=0\n",
    "    epochs=10\n",
    "    encoder_lr=2e-5\n",
    "    decoder_lr=2e-5\n",
    "    min_lr=1e-6\n",
    "    eps=1e-6\n",
    "    betas=(0.9, 0.999)\n",
    "    batch_size=256\n",
    "    fc_dropout=0.1\n",
    "    max_len=512\n",
    "    weight_decay=0.01\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    seed=42\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "    train=True\n",
    "    extra=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "248d9e62-7d84-45a2-bd20-3a9a865d9a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizers.__version__: 0.13.3\n",
      "transformers.__version__: 4.30.1\n",
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "import warnings\n",
    "import ast\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import tokenizers\n",
    "import transformers\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, T5EncoderModel\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "# %env CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a0fa61-0c8d-4f10-82a0-393bf37d9ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(filename=os.path.join(OUTPUT_DIR, \"train\")):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f179e27-68c7-4540-ae2e-0885cb2b92a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def probs2str(results, texts): # (4501, 70, 3)\n",
    "    predictions = []\n",
    "    classes = np.argmax(results, axis=-1)\n",
    "    input_ids_list = [tokenizer(text, \n",
    "                           add_special_tokens=True,\n",
    "                           max_length=CFG.max_len,\n",
    "                           padding=\"max_length\",\n",
    "                           return_offsets_mapping=False)[\"input_ids\"] for text in texts]\n",
    "\n",
    "    for clas, input_ids in zip(classes, input_ids_list):\n",
    "        entities = convert_ids_to_entities(clas, input_ids)\n",
    "\n",
    "        entities = list(itertools.chain(*entities))\n",
    "        # entities = tokenizer.convert_ids_to_tokens(entities)\n",
    "        # entities = [entity for entity in entities if (entity != \"[PAD]\") and (entity != \"[SEP]\")]\n",
    "        # prediction = tokenizer.convert_tokens_to_string(entities)\n",
    "        prediction = tokenizer.decode(entities, skip_special_tokens=True)\n",
    "        prediction = re.sub(\" - \", \"-\", prediction)\n",
    "        prediction = re.sub(\" & \", \"&\", prediction)\n",
    "        prediction = re.sub(\"##\", \"\", prediction)\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def get_score_f1(y_true, y_pred):\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    acc = 0\n",
    "    for tr, pr in zip(y_true, y_pred):\n",
    "        if tr == pr: acc += 1\n",
    "        pr = frozenset([pr])\n",
    "        tr = frozenset([tr])\n",
    "\n",
    "        tp += len(pr & tr)\n",
    "        fp += len(pr - tr)\n",
    "        fn += len(tr - pr)\n",
    "\n",
    "    if tp == 0:\n",
    "        return 0.0\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    print(f\"Accuracy: {acc / len(y_true)}\")\n",
    "    score = 2 / (1 / precision + 1 / recall)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01f9a2e4-37f5-4924-adbf-8bf3bec9b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ids_to_entities(ids, tokens=None, o_id=0, b_id=1, i_id=2):\n",
    "    entities = []\n",
    "    entity = []\n",
    "    is_entity_started = False\n",
    "    for index, token in enumerate(ids):\n",
    "        if not is_entity_started and token == b_id:\n",
    "            is_entity_started = True\n",
    "            entity.append(index)\n",
    "        elif is_entity_started and token == i_id:\n",
    "            entity.append(index)\n",
    "    \n",
    "        if (is_entity_started and token == o_id) or (index == (len(ids) - 1)):\n",
    "            is_entity_started = False\n",
    "            entities.append(entity)\n",
    "            entity = []\n",
    "                \n",
    "    if tokens is not None:\n",
    "        tokens = np.array(tokens)\n",
    "        token_entities = []\n",
    "        for entity in entities:\n",
    "            entity = np.array(entity)\n",
    "            if len(entity) > 0:\n",
    "                token_entity = tokens[entity]\n",
    "                token_entities.append(token_entity.tolist())\n",
    "            \n",
    "        return token_entities\n",
    "            \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4063a6cb-776c-4a1d-9276-d41af23d33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    # text = re.sub(\"_\", \" \", text) # v2e\n",
    "    # text = re.sub(\"\\d{5,}\", \" \", text) # убираю длиньше чем есть в метках\n",
    "    # text = re.sub(\"\\d+[\\.\\,]?\\d* *(см|гр|г|л|мл|кг|шт|мкм|м)\", \" \", text) # убираю единицы измерения\n",
    "    # text = re.sub(\"\\d+[\\.\\,]?\\d*\\s?%\", \" \", text) # процентное содержание в товарах\n",
    "    # text = re.sub(\"\\[.*\\]\", \" \", text) # убираем скобки и содержимое\n",
    "    # text = re.sub(\"<.+>\", \" \", text) # убираем скобки и содержимое\n",
    "    # text = re.sub(\"{.+}\", \" \", text) # убираем скобки и содержимое\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "def get_brand_pos(row):\n",
    "    if row[\"brand\"] == \"\": return (0, 0)\n",
    "    start = row[\"name\"].lower().find(row[\"brand\"])\n",
    "    if start == -1:\n",
    "        end = -1\n",
    "    else:\n",
    "        end = start + len(row[\"brand\"])\n",
    "\n",
    "    return (start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17845f45-e708-4da2-a843-4e99852b9846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22550, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>brand_pos</th>\n",
       "      <th>strat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>petmax бантик леопард с красн розой 2шт</td>\n",
       "      <td>petmax</td>\n",
       "      <td>(0, 6)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87191 бусы для елки шарики_87191</td>\n",
       "      <td></td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>футболка piazza italia wr011446881</td>\n",
       "      <td>piazza italia</td>\n",
       "      <td>(9, 22)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7) yi572-03x-one заколка для волос для девочки</td>\n",
       "      <td></td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>одежда (вес) 1500</td>\n",
       "      <td></td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             name          brand brand_pos  strat\n",
       "0         petmax бантик леопард с красн розой 2шт         petmax    (0, 6)      0\n",
       "1                87191 бусы для елки шарики_87191                   (0, 0)      1\n",
       "2              футболка piazza italia wr011446881  piazza italia   (9, 22)      0\n",
       "3  7) yi572-03x-one заколка для волос для девочки                   (0, 0)      1\n",
       "4                               одежда (вес) 1500                   (0, 0)      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_supervised_dataset.csv\")\n",
    "df = df[[\"name\", \"brand\"]].fillna(\"\")\n",
    "df.name = df.name.apply(preprocess_text)\n",
    "df[\"brand_pos\"] = df.apply(get_brand_pos, axis=1)\n",
    "df = df[df.brand_pos != (-1,-1)].reset_index(drop=True)\n",
    "\n",
    "df[\"strat\"] = df.brand_pos.apply(lambda x: 1 if x == (0, 0) else 0)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a116e0db-1905-4d74-bb10-f58959c8f5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    4510\n",
       "1    4510\n",
       "2    4510\n",
       "3    4510\n",
       "4    4510\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Fold = StratifiedKFold(n_splits=CFG.n_fold)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(df, df.strat.values)):\n",
    "    df.loc[val_index, 'fold'] = int(n)\n",
    "df['fold'] = df['fold'].astype(int)\n",
    "display(df.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7304529c-6a1d-46b7-b8c2-382e4449f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.extra:\n",
    "    extra_data = pd.read_csv(\"unsup_pred_rubert.csv\")\n",
    "    extra_data = extra_data[[\"name\", \"brand\"]].fillna(\"\")\n",
    "    extra_data.name = extra_data.name.apply(preprocess_text)\n",
    "    extra_data[\"brand_pos\"] = extra_data.apply(get_brand_pos, axis=1)\n",
    "    extra_data = extra_data[extra_data.brand_pos != (-1,-1)].reset_index(drop=True)\n",
    "    extra_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1b4c29b-a5fc-44cd-813f-d4cb980650c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# tokenizer\n",
    "# ====================================================\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
    "tokenizer.save_pretrained(os.path.join(OUTPUT_DIR, \"tokenizer\"))\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "646a107d-db84-4d89-955e-f14e797563ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f0c1d86ce34c069fd096de740681bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_len: 66\n"
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "tk0 = tqdm(df.name.values, total=len(df))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "    lengths.append(length)\n",
    "\n",
    "if CFG.extra:\n",
    "    tk1 = tqdm(extra_data.name.values, total=len(extra_data))\n",
    "    for text in tk1:\n",
    "        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "        lengths.append(length)\n",
    "\n",
    "CFG.max_len = max(lengths) + 2 # cls & sep\n",
    "LOGGER.info(f\"max_len: {CFG.max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4b282dc-a8fc-4158-93cf-885b7e9351f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(cfg, text):\n",
    "    inputs = cfg.tokenizer(text, \n",
    "                           add_special_tokens=True,\n",
    "                           max_length=CFG.max_len,\n",
    "                           padding=\"max_length\",\n",
    "                           return_offsets_mapping=False)\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def create_label(cfg, text, annotation, pos):\n",
    "    # \"O\" -> 0\n",
    "    # \"B\" -> 1\n",
    "    # \"I\" -> 2\n",
    "    encoded = cfg.tokenizer(text,\n",
    "                            add_special_tokens=True,\n",
    "                            max_length=CFG.max_len,\n",
    "                            padding=\"max_length\",\n",
    "                            return_offsets_mapping=True)\n",
    "    offset_mapping = encoded['offset_mapping']\n",
    "    ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n",
    "    label = np.zeros(len(offset_mapping))\n",
    "    label[ignore_idxes] = -1\n",
    "\n",
    "    if pos == (0, 0):\n",
    "        return torch.tensor(label, dtype=torch.long)\n",
    "    for i in range(len(offset_mapping)):\n",
    "        if offset_mapping[i] == (0, 0):\n",
    "            continue\n",
    "        elif offset_mapping[i][0] == pos[0]:\n",
    "            label[i] = 1\n",
    "        elif offset_mapping[i][1] <= pos[1] and offset_mapping[i][0] >= pos[0]:\n",
    "            label[i] = 2\n",
    "\n",
    "    return torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.name = df['name'].values\n",
    "        self.brand = df['brand'].values\n",
    "        self.brand_pos = df['brand_pos'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.name)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, \n",
    "                               self.name[item])\n",
    "        label = create_label(self.cfg, \n",
    "                             self.name[item], \n",
    "                             self.brand[item], \n",
    "                             self.brand_pos[item])\n",
    "        return inputs, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93b662a4-2fdb-4814-9c73-ec5ea0ab37b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel(self.config)\n",
    "        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 3)\n",
    "        self._init_weights(self.fc)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        return last_hidden_states\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(self.fc_dropout(feature))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f62c135b-df76-41f1-a542-3a74b29b3d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86d2b687-f9f6-40e1-a2e2-fb34914bd42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    global_step = 0\n",
    "    for step, (inputs, labels) in enumerate(train_loader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            y_preds = model(inputs)\n",
    "        loss = criterion(y_preds.transpose(1, 2), labels)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch+1, step, len(train_loader), \n",
    "                          remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                          loss=losses,\n",
    "                          grad_norm=grad_norm,\n",
    "                          lr=scheduler.get_lr()[0]))\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d838e9a-1648-41e3-86cd-0082807e5e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (inputs, labels) in enumerate(valid_loader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        loss = criterion(y_preds.transpose(1, 2), labels)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(y_preds.softmax(-1).to('cpu').numpy()) ####\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, len(valid_loader),\n",
    "                          loss=losses,\n",
    "                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "412952ad-5b7e-46dd-855f-57e9cbbffe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(folds, fold):\n",
    "    \n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n",
    "\n",
    "    if CFG.extra:\n",
    "        train_folds = pd.concat([train_folds, extra_data], axis=0)\n",
    "    \n",
    "    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n",
    "    valid_texts = valid_folds['name'].values\n",
    "    valid_labels = valid_folds['brand'].values\n",
    "    \n",
    "    train_dataset = TrainDataset(CFG, train_folds)\n",
    "    valid_dataset = TrainDataset(CFG, valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = CustomModel(CFG, config_path=None, pretrained=True)\n",
    "    torch.save(model.config, os.path.join(OUTPUT_DIR, \"config.pth\"))\n",
    "    model.to(device)\n",
    "    \n",
    "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "             'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "\n",
    "    optimizer_parameters = get_optimizer_params(model,\n",
    "                                                encoder_lr=CFG.encoder_lr, \n",
    "                                                decoder_lr=CFG.decoder_lr,\n",
    "                                                weight_decay=CFG.weight_decay)\n",
    "    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n",
    "    \n",
    "    # ====================================================\n",
    "    # scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "        if cfg.scheduler=='linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif cfg.scheduler=='cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
    "            )\n",
    "        return scheduler\n",
    "    \n",
    "    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n",
    "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "    \n",
    "    best_score = 0.0\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n",
    "        # scoring\n",
    "        preds = probs2str(predictions, valid_texts)\n",
    "        score = get_score_f1(valid_labels, preds)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n",
    "        \n",
    "        if best_score < score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'predictions': np.argmax(predictions, axis=-1)},\n",
    "                        os.path.join(OUTPUT_DIR, f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\"))\n",
    "\n",
    "    predictions = torch.load(os.path.join(OUTPUT_DIR, f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\"), \n",
    "                             map_location=torch.device('cpu'))['predictions']\n",
    "    valid_folds[[i for i in range(CFG.max_len)]] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ac07b17-a16c-474f-89d1-f8e87b0d46ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/70] Elapsed 0m 1s (remain 1m 11s) Loss: 1.0273(1.0273) Grad: nan  LR: 0.00001997  \n",
      "Epoch: [1][69/70] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0976(0.2759) Grad: 10076.9023  LR: 0.00001801  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1009(0.1009) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0956(0.0999) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.2759  avg_val_loss: 0.0999  time: 23s\n",
      "Epoch 1 - Score: 0.7497\n",
      "Epoch 1 - Save Best Score: 0.7497 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7496674057649667\n",
      "Epoch: [2][0/70] Elapsed 0m 0s (remain 0m 30s) Loss: 0.1114(0.1114) Grad: nan  LR: 0.00001798  \n",
      "Epoch: [2][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0762(0.0935) Grad: 16474.7168  LR: 0.00001602  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0782(0.0782) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0791(0.0824) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.0935  avg_val_loss: 0.0824  time: 22s\n",
      "Epoch 2 - Score: 0.7960\n",
      "Epoch 2 - Save Best Score: 0.7960 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7960088691796009\n",
      "Epoch: [3][0/70] Elapsed 0m 0s (remain 0m 30s) Loss: 0.1038(0.1038) Grad: nan  LR: 0.00001599  \n",
      "Epoch: [3][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0732(0.0769) Grad: 17449.3750  LR: 0.00001403  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0696(0.0696) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0654(0.0774) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.0769  avg_val_loss: 0.0774  time: 23s\n",
      "Epoch 3 - Score: 0.8129\n",
      "Epoch 3 - Save Best Score: 0.8129 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.812860310421286\n",
      "Epoch: [4][0/70] Elapsed 0m 0s (remain 0m 30s) Loss: 0.0720(0.0720) Grad: nan  LR: 0.00001401  \n",
      "Epoch: [4][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0611(0.0666) Grad: 17592.6348  LR: 0.00001205  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0648(0.0648) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0635(0.0725) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.0666  avg_val_loss: 0.0725  time: 23s\n",
      "Epoch 4 - Score: 0.8233\n",
      "Epoch 4 - Save Best Score: 0.8233 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8232815964523281\n",
      "Epoch: [5][0/70] Elapsed 0m 0s (remain 0m 30s) Loss: 0.0668(0.0668) Grad: nan  LR: 0.00001202  \n",
      "Epoch: [5][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0569(0.0584) Grad: 18966.6621  LR: 0.00001006  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0643(0.0643) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0600(0.0719) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.0584  avg_val_loss: 0.0719  time: 23s\n",
      "Epoch 5 - Score: 0.8341\n",
      "Epoch 5 - Save Best Score: 0.8341 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8341463414634146\n",
      "Epoch: [6][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0441(0.0441) Grad: nan  LR: 0.00001003  \n",
      "Epoch: [6][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0537(0.0537) Grad: 16371.0225  LR: 0.00000807  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0618(0.0618) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0599(0.0724) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.0537  avg_val_loss: 0.0724  time: 23s\n",
      "Epoch 6 - Score: 0.8384\n",
      "Epoch 6 - Save Best Score: 0.8384 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8383592017738359\n",
      "Epoch: [7][0/70] Elapsed 0m 0s (remain 0m 30s) Loss: 0.0540(0.0540) Grad: nan  LR: 0.00000804  \n",
      "Epoch: [7][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0468(0.0483) Grad: 18967.0449  LR: 0.00000608  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0602(0.0602) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0598(0.0721) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.0483  avg_val_loss: 0.0721  time: 23s\n",
      "Epoch 7 - Score: 0.8406\n",
      "Epoch 7 - Save Best Score: 0.8406 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8405764966740576\n",
      "Epoch: [8][0/70] Elapsed 0m 0s (remain 0m 30s) Loss: 0.0381(0.0381) Grad: nan  LR: 0.00000605  \n",
      "Epoch: [8][69/70] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0449(0.0454) Grad: 20356.7109  LR: 0.00000409  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0602(0.0602) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0598(0.0743) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.0454  avg_val_loss: 0.0743  time: 23s\n",
      "Epoch 8 - Score: 0.8439\n",
      "Epoch 8 - Save Best Score: 0.8439 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8439024390243902\n",
      "Epoch: [9][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0504(0.0504) Grad: nan  LR: 0.00000406  \n",
      "Epoch: [9][69/70] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0469(0.0430) Grad: 22693.1641  LR: 0.00000210  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0604(0.0604) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0603(0.0739) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.0430  avg_val_loss: 0.0739  time: 23s\n",
      "Epoch 9 - Score: 0.8481\n",
      "Epoch 9 - Save Best Score: 0.8481 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8481152993348116\n",
      "Epoch: [10][0/70] Elapsed 0m 0s (remain 0m 29s) Loss: 0.0364(0.0364) Grad: nan  LR: 0.00000207  \n",
      "Epoch: [10][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0348(0.0420) Grad: 17028.9727  LR: 0.00000011  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0598(0.0598) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0600(0.0742) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.0420  avg_val_loss: 0.0742  time: 22s\n",
      "Epoch 10 - Score: 0.8475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.847450110864745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 result ==========\n",
      "Score: 0.8481\n",
      "========== fold: 1 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8481152993348116\n",
      "Epoch: [1][0/70] Elapsed 0m 0s (remain 0m 29s) Loss: 1.1787(1.1787) Grad: nan  LR: 0.00001997  \n",
      "Epoch: [1][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.1140(0.2842) Grad: 9645.5537  LR: 0.00001801  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0977(0.0977) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.1115(0.0999) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.2842  avg_val_loss: 0.0999  time: 22s\n",
      "Epoch 1 - Score: 0.7457\n",
      "Epoch 1 - Save Best Score: 0.7457 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7456762749445677\n",
      "Epoch: [2][0/70] Elapsed 0m 0s (remain 0m 30s) Loss: 0.1159(0.1159) Grad: nan  LR: 0.00001798  \n",
      "Epoch: [2][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0937(0.0954) Grad: 20945.8965  LR: 0.00001602  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0769(0.0769) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.1014(0.0802) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.0954  avg_val_loss: 0.0802  time: 22s\n",
      "Epoch 2 - Score: 0.7945\n",
      "Epoch 2 - Save Best Score: 0.7945 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7944567627494457\n",
      "Epoch: [3][0/70] Elapsed 0m 0s (remain 0m 30s) Loss: 0.0877(0.0877) Grad: nan  LR: 0.00001599  \n",
      "Epoch: [3][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0908(0.0782) Grad: 28223.1035  LR: 0.00001403  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0694(0.0694) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.1007(0.0736) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.0782  avg_val_loss: 0.0736  time: 22s\n",
      "Epoch 3 - Score: 0.8177\n",
      "Epoch 3 - Save Best Score: 0.8177 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8177383592017738\n",
      "Epoch: [4][0/70] Elapsed 0m 0s (remain 0m 30s) Loss: 0.0563(0.0563) Grad: nan  LR: 0.00001401  \n",
      "Epoch: [4][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0621(0.0659) Grad: 19802.7891  LR: 0.00001205  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0678(0.0678) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0978(0.0716) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.0659  avg_val_loss: 0.0716  time: 22s\n",
      "Epoch 4 - Score: 0.8257\n",
      "Epoch 4 - Save Best Score: 0.8257 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.825720620842572\n",
      "Epoch: [5][0/70] Elapsed 0m 0s (remain 0m 29s) Loss: 0.0626(0.0626) Grad: nan  LR: 0.00001202  \n",
      "Epoch: [5][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0429(0.0587) Grad: 13316.1592  LR: 0.00001006  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0680(0.0680) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0999(0.0711) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.0587  avg_val_loss: 0.0711  time: 22s\n",
      "Epoch 5 - Score: 0.8337\n",
      "Epoch 5 - Save Best Score: 0.8337 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8337028824833703\n",
      "Epoch: [6][0/70] Elapsed 0m 0s (remain 0m 29s) Loss: 0.0552(0.0552) Grad: nan  LR: 0.00001003  \n",
      "Epoch: [6][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0389(0.0530) Grad: 18567.4512  LR: 0.00000807  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0735(0.0735) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.1055(0.0727) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.0530  avg_val_loss: 0.0727  time: 22s\n",
      "Epoch 6 - Score: 0.8379\n",
      "Epoch 6 - Save Best Score: 0.8379 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8379157427937916\n",
      "Epoch: [7][0/70] Elapsed 0m 0s (remain 0m 29s) Loss: 0.0478(0.0478) Grad: nan  LR: 0.00000804  \n",
      "Epoch: [7][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0501(0.0490) Grad: 18513.2148  LR: 0.00000608  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0709(0.0709) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.1016(0.0718) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.0490  avg_val_loss: 0.0718  time: 22s\n",
      "Epoch 7 - Score: 0.8381\n",
      "Epoch 7 - Save Best Score: 0.8381 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8381374722838137\n",
      "Epoch: [8][0/70] Elapsed 0m 0s (remain 0m 29s) Loss: 0.0313(0.0313) Grad: nan  LR: 0.00000605  \n",
      "Epoch: [8][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0377(0.0452) Grad: 16091.1514  LR: 0.00000409  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0728(0.0728) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.1014(0.0720) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.0452  avg_val_loss: 0.0720  time: 22s\n",
      "Epoch 8 - Score: 0.8408\n",
      "Epoch 8 - Save Best Score: 0.8408 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8407982261640798\n",
      "Epoch: [9][0/70] Elapsed 0m 0s (remain 0m 29s) Loss: 0.0380(0.0380) Grad: nan  LR: 0.00000406  \n",
      "Epoch: [9][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0441(0.0438) Grad: 21531.3730  LR: 0.00000210  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0731(0.0731) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.1023(0.0730) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.0438  avg_val_loss: 0.0730  time: 22s\n",
      "Epoch 9 - Score: 0.8437\n",
      "Epoch 9 - Save Best Score: 0.8437 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.843680709534368\n",
      "Epoch: [10][0/70] Elapsed 0m 0s (remain 0m 29s) Loss: 0.0513(0.0513) Grad: nan  LR: 0.00000207  \n",
      "Epoch: [10][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0340(0.0425) Grad: 12786.0098  LR: 0.00000011  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0741(0.0741) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.1041(0.0733) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.0425  avg_val_loss: 0.0733  time: 22s\n",
      "Epoch 10 - Score: 0.8437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.843680709534368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 1 result ==========\n",
      "Score: 0.8437\n",
      "========== fold: 2 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.843680709534368\n",
      "Epoch: [1][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 1.1777(1.1777) Grad: nan  LR: 0.00001997  \n",
      "Epoch: [1][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.1190(0.2936) Grad: 8814.3916  LR: 0.00001801  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1082(0.1082) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0787(0.1071) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.2936  avg_val_loss: 0.1071  time: 22s\n",
      "Epoch 1 - Score: 0.7554\n",
      "Epoch 1 - Save Best Score: 0.7554 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7554323725055433\n",
      "Epoch: [2][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.1034(0.1034) Grad: nan  LR: 0.00001798  \n",
      "Epoch: [2][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0829(0.0935) Grad: 16771.7891  LR: 0.00001602  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0879(0.0879) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0617(0.0855) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.0935  avg_val_loss: 0.0855  time: 22s\n",
      "Epoch 2 - Score: 0.7947\n",
      "Epoch 2 - Save Best Score: 0.7947 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7946784922394678\n",
      "Epoch: [3][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0871(0.0871) Grad: nan  LR: 0.00001599  \n",
      "Epoch: [3][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0763(0.0760) Grad: 21244.5254  LR: 0.00001403  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0879(0.0879) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0575(0.0809) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.0760  avg_val_loss: 0.0809  time: 22s\n",
      "Epoch 3 - Score: 0.8124\n",
      "Epoch 3 - Save Best Score: 0.8124 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8124168514412416\n",
      "Epoch: [4][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0727(0.0727) Grad: nan  LR: 0.00001401  \n",
      "Epoch: [4][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0666(0.0655) Grad: 21042.4395  LR: 0.00001205  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0854(0.0854) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0590(0.0782) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.0655  avg_val_loss: 0.0782  time: 22s\n",
      "Epoch 4 - Score: 0.8239\n",
      "Epoch 4 - Save Best Score: 0.8239 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8239467849223947\n",
      "Epoch: [5][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0764(0.0764) Grad: nan  LR: 0.00001202  \n",
      "Epoch: [5][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0528(0.0585) Grad: 18091.9727  LR: 0.00001006  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0839(0.0839) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0605(0.0768) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.0585  avg_val_loss: 0.0768  time: 22s\n",
      "Epoch 5 - Score: 0.8279\n",
      "Epoch 5 - Save Best Score: 0.8279 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8279379157427937\n",
      "Epoch: [6][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0468(0.0468) Grad: nan  LR: 0.00001003  \n",
      "Epoch: [6][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0539(0.0532) Grad: 17755.1426  LR: 0.00000807  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0843(0.0843) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0570(0.0758) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.0532  avg_val_loss: 0.0758  time: 22s\n",
      "Epoch 6 - Score: 0.8364\n",
      "Epoch 6 - Save Best Score: 0.8364 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8363636363636363\n",
      "Epoch: [7][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0542(0.0542) Grad: nan  LR: 0.00000804  \n",
      "Epoch: [7][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0544(0.0480) Grad: 20246.7578  LR: 0.00000608  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0846(0.0846) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0574(0.0765) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.0480  avg_val_loss: 0.0765  time: 22s\n",
      "Epoch 7 - Score: 0.8377\n",
      "Epoch 7 - Save Best Score: 0.8377 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8376940133037694\n",
      "Epoch: [8][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0328(0.0328) Grad: nan  LR: 0.00000605  \n",
      "Epoch: [8][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0432(0.0452) Grad: 19368.6309  LR: 0.00000409  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0885(0.0885) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0612(0.0789) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.0452  avg_val_loss: 0.0789  time: 22s\n",
      "Epoch 8 - Score: 0.8415\n",
      "Epoch 8 - Save Best Score: 0.8415 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8414634146341463\n",
      "Epoch: [9][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0453(0.0453) Grad: nan  LR: 0.00000406  \n",
      "Epoch: [9][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0418(0.0427) Grad: 16723.3027  LR: 0.00000210  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0889(0.0889) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0611(0.0807) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.0427  avg_val_loss: 0.0807  time: 22s\n",
      "Epoch 9 - Score: 0.8410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.841019955654102\n",
      "Epoch: [10][0/70] Elapsed 0m 0s (remain 0m 30s) Loss: 0.0356(0.0356) Grad: nan  LR: 0.00000207  \n",
      "Epoch: [10][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0350(0.0406) Grad: 19048.0352  LR: 0.00000011  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0884(0.0884) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0608(0.0807) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.0406  avg_val_loss: 0.0807  time: 22s\n",
      "Epoch 10 - Score: 0.8417\n",
      "Epoch 10 - Save Best Score: 0.8417 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8416851441241685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 2 result ==========\n",
      "Score: 0.8417\n",
      "========== fold: 3 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8416851441241685\n",
      "Epoch: [1][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.9199(0.9199) Grad: nan  LR: 0.00001997  \n",
      "Epoch: [1][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.1101(0.2707) Grad: 10412.8701  LR: 0.00001801  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0954(0.0954) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0909(0.1024) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.2707  avg_val_loss: 0.1024  time: 22s\n",
      "Epoch 1 - Score: 0.7435\n",
      "Epoch 1 - Save Best Score: 0.7435 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7434589800443459\n",
      "Epoch: [2][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.1078(0.1078) Grad: nan  LR: 0.00001798  \n",
      "Epoch: [2][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0725(0.0948) Grad: 21185.2988  LR: 0.00001602  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0780(0.0780) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0699(0.0832) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.0948  avg_val_loss: 0.0832  time: 22s\n",
      "Epoch 2 - Score: 0.7885\n",
      "Epoch 2 - Save Best Score: 0.7885 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.788470066518847\n",
      "Epoch: [3][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0705(0.0705) Grad: nan  LR: 0.00001599  \n",
      "Epoch: [3][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0817(0.0774) Grad: 18191.3242  LR: 0.00001403  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0678(0.0678) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0654(0.0750) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.0774  avg_val_loss: 0.0750  time: 22s\n",
      "Epoch 3 - Score: 0.8049\n",
      "Epoch 3 - Save Best Score: 0.8049 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8048780487804879\n",
      "Epoch: [4][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0721(0.0721) Grad: nan  LR: 0.00001401  \n",
      "Epoch: [4][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0615(0.0658) Grad: 16123.3037  LR: 0.00001205  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0673(0.0673) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0641(0.0712) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.0658  avg_val_loss: 0.0712  time: 22s\n",
      "Epoch 4 - Score: 0.8213\n",
      "Epoch 4 - Save Best Score: 0.8213 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8212860310421286\n",
      "Epoch: [5][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0541(0.0541) Grad: nan  LR: 0.00001202  \n",
      "Epoch: [5][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0599(0.0586) Grad: 19298.9824  LR: 0.00001006  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0661(0.0661) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0612(0.0704) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.0586  avg_val_loss: 0.0704  time: 22s\n",
      "Epoch 5 - Score: 0.8264\n",
      "Epoch 5 - Save Best Score: 0.8264 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8263858093126386\n",
      "Epoch: [6][0/70] Elapsed 0m 0s (remain 0m 33s) Loss: 0.0856(0.0856) Grad: nan  LR: 0.00001003  \n",
      "Epoch: [6][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0522(0.0529) Grad: 20855.8027  LR: 0.00000807  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0653(0.0653) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0627(0.0704) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.0529  avg_val_loss: 0.0704  time: 22s\n",
      "Epoch 6 - Score: 0.8335\n",
      "Epoch 6 - Save Best Score: 0.8335 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8334811529933481\n",
      "Epoch: [7][0/70] Elapsed 0m 0s (remain 0m 33s) Loss: 0.0602(0.0602) Grad: nan  LR: 0.00000804  \n",
      "Epoch: [7][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0437(0.0487) Grad: 18832.4219  LR: 0.00000608  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0673(0.0673) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0661(0.0699) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.0487  avg_val_loss: 0.0699  time: 22s\n",
      "Epoch 7 - Score: 0.8399\n",
      "Epoch 7 - Save Best Score: 0.8399 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8399113082039912\n",
      "Epoch: [8][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0428(0.0428) Grad: nan  LR: 0.00000605  \n",
      "Epoch: [8][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0468(0.0457) Grad: 20667.7109  LR: 0.00000409  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0680(0.0680) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0691(0.0717) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.0457  avg_val_loss: 0.0717  time: 22s\n",
      "Epoch 8 - Score: 0.8410\n",
      "Epoch 8 - Save Best Score: 0.8410 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.841019955654102\n",
      "Epoch: [9][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0466(0.0466) Grad: nan  LR: 0.00000406  \n",
      "Epoch: [9][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0346(0.0427) Grad: 16414.6484  LR: 0.00000210  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0690(0.0690) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0675(0.0711) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.0427  avg_val_loss: 0.0711  time: 22s\n",
      "Epoch 9 - Score: 0.8437\n",
      "Epoch 9 - Save Best Score: 0.8437 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.843680709534368\n",
      "Epoch: [10][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0400(0.0400) Grad: nan  LR: 0.00000207  \n",
      "Epoch: [10][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0509(0.0415) Grad: 17328.4180  LR: 0.00000011  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0699(0.0699) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0681(0.0714) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.0415  avg_val_loss: 0.0714  time: 22s\n",
      "Epoch 10 - Score: 0.8439\n",
      "Epoch 10 - Save Best Score: 0.8439 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8439024390243902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 3 result ==========\n",
      "Score: 0.8439\n",
      "========== fold: 4 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8439024390243902\n",
      "Epoch: [1][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 1.1768(1.1768) Grad: nan  LR: 0.00001997  \n",
      "Epoch: [1][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.1088(0.2816) Grad: 9081.4629  LR: 0.00001801  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1008(0.1008) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0883(0.1018) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.2816  avg_val_loss: 0.1018  time: 22s\n",
      "Epoch 1 - Score: 0.7530\n",
      "Epoch 1 - Save Best Score: 0.7530 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7529933481152994\n",
      "Epoch: [2][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.1035(0.1035) Grad: nan  LR: 0.00001798  \n",
      "Epoch: [2][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.1062(0.0919) Grad: 23465.3555  LR: 0.00001602  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0783(0.0783) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0638(0.0809) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.0919  avg_val_loss: 0.0809  time: 22s\n",
      "Epoch 2 - Score: 0.7967\n",
      "Epoch 2 - Save Best Score: 0.7967 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7966740576496674\n",
      "Epoch: [3][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0800(0.0800) Grad: nan  LR: 0.00001599  \n",
      "Epoch: [3][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0809(0.0763) Grad: 19930.5586  LR: 0.00001403  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0783(0.0783) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0586(0.0749) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.0763  avg_val_loss: 0.0749  time: 22s\n",
      "Epoch 3 - Score: 0.8111\n",
      "Epoch 3 - Save Best Score: 0.8111 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8110864745011086\n",
      "Epoch: [4][0/70] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0632(0.0632) Grad: nan  LR: 0.00001401  \n",
      "Epoch: [4][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0609(0.0667) Grad: 19902.0898  LR: 0.00001205  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0763(0.0763) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0562(0.0715) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.0667  avg_val_loss: 0.0715  time: 22s\n",
      "Epoch 4 - Score: 0.8302\n",
      "Epoch 4 - Save Best Score: 0.8302 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8301552106430156\n",
      "Epoch: [5][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0732(0.0732) Grad: nan  LR: 0.00001202  \n",
      "Epoch: [5][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0399(0.0592) Grad: 16794.2773  LR: 0.00001006  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0730(0.0730) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0512(0.0687) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.0592  avg_val_loss: 0.0687  time: 22s\n",
      "Epoch 5 - Score: 0.8366\n",
      "Epoch 5 - Save Best Score: 0.8366 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8365853658536585\n",
      "Epoch: [6][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0477(0.0477) Grad: nan  LR: 0.00001003  \n",
      "Epoch: [6][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0525(0.0532) Grad: 16148.2451  LR: 0.00000807  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0732(0.0732) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0499(0.0691) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.0532  avg_val_loss: 0.0691  time: 22s\n",
      "Epoch 6 - Score: 0.8392\n",
      "Epoch 6 - Save Best Score: 0.8392 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8392461197339246\n",
      "Epoch: [7][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0479(0.0479) Grad: nan  LR: 0.00000804  \n",
      "Epoch: [7][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0441(0.0502) Grad: 16778.5234  LR: 0.00000608  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0719(0.0719) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0507(0.0681) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.0502  avg_val_loss: 0.0681  time: 22s\n",
      "Epoch 7 - Score: 0.8443\n",
      "Epoch 7 - Save Best Score: 0.8443 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8443458980044346\n",
      "Epoch: [8][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0528(0.0528) Grad: nan  LR: 0.00000605  \n",
      "Epoch: [8][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0402(0.0461) Grad: 15859.8428  LR: 0.00000409  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0742(0.0742) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0504(0.0692) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.0461  avg_val_loss: 0.0692  time: 22s\n",
      "Epoch 8 - Score: 0.8448\n",
      "Epoch 8 - Save Best Score: 0.8448 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.844789356984479\n",
      "Epoch: [9][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0479(0.0479) Grad: nan  LR: 0.00000406  \n",
      "Epoch: [9][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0428(0.0444) Grad: 19235.4746  LR: 0.00000210  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0748(0.0748) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0527(0.0691) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.0444  avg_val_loss: 0.0691  time: 22s\n",
      "Epoch 9 - Score: 0.8443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8443458980044346\n",
      "Epoch: [10][0/70] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0428(0.0428) Grad: nan  LR: 0.00000207  \n",
      "Epoch: [10][69/70] Elapsed 0m 18s (remain 0m 0s) Loss: 0.0441(0.0428) Grad: 18080.6465  LR: 0.00000011  \n",
      "EVAL: [0/18] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0758(0.0758) \n",
      "EVAL: [17/18] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0520(0.0694) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.0428  avg_val_loss: 0.0694  time: 22s\n",
      "Epoch 10 - Score: 0.8446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8445676274944568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 4 result ==========\n",
      "Score: 0.8448\n",
      "========== CV ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.844789356984479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Score: 0.8444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8444345898004435\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    def get_result(oof_df):\n",
    "        predictions = []\n",
    "        classes = oof_df[[i for i in range(CFG.max_len)]].values.tolist()\n",
    "        input_ids_list = [CFG.tokenizer(text, \n",
    "                           add_special_tokens=True,\n",
    "                           max_length=CFG.max_len,\n",
    "                           padding=\"max_length\",\n",
    "                           return_offsets_mapping=False)[\"input_ids\"] for text in oof_df.name.values]\n",
    "        for clas, input_ids in zip(classes, input_ids_list):\n",
    "            entities = convert_ids_to_entities(clas, input_ids)\n",
    "    \n",
    "            entities = list(itertools.chain(*entities))\n",
    "            # entities = tokenizer.convert_ids_to_tokens(entities)\n",
    "            # entities = [entity for entity in entities if entity != \"[PAD]\"]\n",
    "            # prediction = tokenizer.convert_tokens_to_string(entities)\n",
    "            prediction = tokenizer.decode(entities, skip_special_tokens=True)\n",
    "            prediction = re.sub(\" - \", \"-\", prediction)\n",
    "            prediction = re.sub(\" & \", \"&\", prediction)\n",
    "            prediction = re.sub(\"##\", \"\", prediction)\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        score = get_score_f1(oof_df.brand.values, predictions)\n",
    "        LOGGER.info(f'Score: {score:<.4f}')\n",
    "    \n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df = train_loop(df, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                get_result(_oof_df)\n",
    "        oof_df = oof_df.reset_index(drop=True)\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "        oof_df.to_pickle(os.path.join(OUTPUT_DIR, \"oof_df.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae4d6d-a762-48d6-8e15-f6d24323208d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3516e80a-47e2-482f-8d2c-5624227f5a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c476c18-25c9-49d2-9ee2-20119ad0a5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111fcf85-b5e9-4172-985b-c3a2a125308a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc264600-ee9b-4ab2-9c19-14d6942cac8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdc1353-7fbb-4086-914e-82c24a3d1636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf67f9a6-cb42-4ea2-9e66-2b095f24fbf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bc3775-ca94-4ea1-952b-bf2eec5b0361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f9e65b-29f3-4ee7-b3af-192d36d69fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261717da-2eee-4b5d-afea-a88c1f7d783c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

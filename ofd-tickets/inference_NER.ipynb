{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecf2c252-7def-4a20-b662-e874a260d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class CFG_good:\n",
    "    num_workers=10\n",
    "    path=\"labse_v4_good\"\n",
    "    config_path=os.path.join(path, \"config.pth\")\n",
    "    model=\"sentence-transformers/LaBSE\"\n",
    "    batch_size=32\n",
    "    fc_dropout=0.1\n",
    "    max_len=66\n",
    "    seed=42\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "\n",
    "class CFG_brand:\n",
    "    num_workers=10\n",
    "    path=\"labse_v4_brand\"\n",
    "    config_path=os.path.join(path, \"config.pth\")\n",
    "    model=\"sentence-transformers/LaBSE\"\n",
    "    batch_size=32\n",
    "    fc_dropout=0.1\n",
    "    max_len=66\n",
    "    seed=42\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96708c8e-4399-4701-9d06-c1ad767bddf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizers.__version__: 0.13.3\n",
      "transformers.__version__: 4.30.1\n",
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import tokenizers\n",
    "import transformers\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce4d1808-6719-45fb-abe4-f8219efea4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probs2str_good(results, texts): # (4501, 70, 3)\n",
    "    predictions = []\n",
    "    classes = np.argmax(results, axis=-1)\n",
    "    input_ids_list = [CFG_good.tokenizer(text, \n",
    "                           add_special_tokens=True,\n",
    "                           max_length=CFG_good.max_len,\n",
    "                           padding=\"max_length\",\n",
    "                           return_offsets_mapping=False)[\"input_ids\"] for text in texts]\n",
    "\n",
    "    for clas, input_ids in zip(classes, input_ids_list):\n",
    "        entities = convert_ids_to_entities(clas, input_ids)\n",
    "\n",
    "        entities = list(itertools.chain(*entities))\n",
    "        prediction = CFG_good.tokenizer.decode(entities, skip_special_tokens=True)\n",
    "        prediction = re.sub(\" - \", \"-\", prediction)\n",
    "        prediction = re.sub(\" & \", \"&\", prediction)\n",
    "        prediction = re.sub(\"##\", \"\", prediction)\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def probs2str_brand(results, texts): # (4501, 70, 3)\n",
    "    predictions = []\n",
    "    classes = np.argmax(results, axis=-1)\n",
    "    input_ids_list = [CFG_brand.tokenizer(text, \n",
    "                           add_special_tokens=True,\n",
    "                           max_length=CFG_brand.max_len,\n",
    "                           padding=\"max_length\",\n",
    "                           return_offsets_mapping=False)[\"input_ids\"] for text in texts]\n",
    "\n",
    "    for clas, input_ids in zip(classes, input_ids_list):\n",
    "        entities = convert_ids_to_entities(clas, input_ids)\n",
    "\n",
    "        entities = list(itertools.chain(*entities))\n",
    "        prediction = CFG_brand.tokenizer.decode(entities, skip_special_tokens=True)\n",
    "        prediction = re.sub(\" - \", \"-\", prediction)\n",
    "        prediction = re.sub(\" & \", \"&\", prediction)\n",
    "        prediction = re.sub(\"##\", \"\", prediction)\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def convert_ids_to_entities(ids, tokens=None, o_id=0, b_id=1, i_id=2):\n",
    "    entities = []\n",
    "    entity = []\n",
    "    is_entity_started = False\n",
    "    for index, token in enumerate(ids):\n",
    "        if not is_entity_started and token == b_id:\n",
    "            is_entity_started = True\n",
    "            entity.append(index)\n",
    "        elif is_entity_started and token == i_id:\n",
    "            entity.append(index)\n",
    "    \n",
    "        if (is_entity_started and token == o_id) or (index == (len(ids) - 1)):\n",
    "            is_entity_started = False\n",
    "            entities.append(entity)\n",
    "            entity = []\n",
    "                \n",
    "    if tokens is not None:\n",
    "        tokens = np.array(tokens)\n",
    "        token_entities = []\n",
    "        for entity in entities:\n",
    "            entity = np.array(entity)\n",
    "            if len(entity) > 0:\n",
    "                token_entity = tokens[entity]\n",
    "                token_entities.append(token_entity.tolist())\n",
    "            \n",
    "        return token_entities\n",
    "            \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f758942-48a7-4d7c-99ae-7b700db49659",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG_good.tokenizer = AutoTokenizer.from_pretrained(os.path.join(CFG_good.path, \"tokenizer\"))\n",
    "CFG_brand.tokenizer = AutoTokenizer.from_pretrained(os.path.join(CFG_brand.path, \"tokenizer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b7591c3-bb4c-4cf7-aa18-f6ecf79c542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(filename=os.path.join(CFG_good.path, \"inference\")):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0453d50-3d52-44df-a2ed-8a47d94caf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.shape: (5000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>469-210 ермак клей универсальный, 15мл, блистер</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>торт сладушка зимняя вишня 700г</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>смеситель \"calorie\" 1023 а06 д/кухни</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>лимон 50гр бар</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>коньяк сараджишвили 5 лет 0,5л грузия</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             name\n",
       "0   0  469-210 ермак клей универсальный, 15мл, блистер\n",
       "1   1                  торт сладушка зимняя вишня 700г\n",
       "2   2             смеситель \"calorie\" 1023 а06 д/кухни\n",
       "3   3                                   лимон 50гр бар\n",
       "4   4            коньяк сараджишвили 5 лет 0,5л грузия"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = pd.read_csv('test_dataset.csv')\n",
    "test.name = test.name.apply(lambda x: x.lower())\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "unsup = pd.read_csv(\"train_unsupervised_dataset.csv\")\n",
    "unsup.name = unsup.name.apply(lambda x: x.lower())\n",
    "\n",
    "print(f\"test.shape: {test.shape}\")\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "837dc471-edd2-4a40-9a89-97aab55a62bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(cfg, text):\n",
    "    inputs = cfg.tokenizer(text, \n",
    "                           add_special_tokens=True,\n",
    "                           max_length=cfg.max_len,\n",
    "                           padding=\"max_length\",\n",
    "                           return_offsets_mapping=False,\n",
    "                          truncation=True)\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    return inputs\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.name = df['name'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.name)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, \n",
    "                               self.name[item])\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0e30077-88b8-49eb-af2d-09e6a62a02aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 3)\n",
    "        self._init_weights(self.fc)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        return last_hidden_states\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(self.fc_dropout(feature))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7593bab-a3ff-4686-8c2b-0c7f3afda75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_fn(test_loader, model, device):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    for inputs in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.softmax(-1).to('cpu').numpy())\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9a916df-dbf2-4c72-8ab9-4d88402cf1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_good = TestDataset(CFG_good, test)\n",
    "test_loader_good = DataLoader(test_dataset_good,\n",
    "                         batch_size=CFG_good.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=CFG_good.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "test_dataset_brand = TestDataset(CFG_brand, test)\n",
    "test_loader_brand = DataLoader(test_dataset_brand,\n",
    "                         batch_size=CFG_brand.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=CFG_brand.num_workers, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eea2f73c-2ff9-495d-91a6-93678645da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsup_dataset_good = TestDataset(CFG_good, unsup)\n",
    "unsup_loader_good = DataLoader(unsup_dataset_good,\n",
    "                         batch_size=CFG_good.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=CFG_good.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "unsup_dataset_brand = TestDataset(CFG_brand, unsup)\n",
    "unsup_loader_brand = DataLoader(unsup_dataset_brand,\n",
    "                         batch_size=CFG_brand.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=CFG_brand.num_workers, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a187084c-2f67-4725-a4ea-0761398367af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d042cf0201944fe4915cb46e569f3b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18659507c4154789937a8ddf7ab54a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2759c21c0a7d498a8c992b43e72bd03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05d8bdbc6bb4abcbff1e008f771d3e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb534c9a4cc4b0e8f66b8e706d4cfc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_good = []\n",
    "for fold in CFG_good.trn_fold:\n",
    "    model = CustomModel(CFG_good, config_path=CFG_good.config_path, pretrained=False)\n",
    "    state = torch.load(os.path.join(CFG_good.path, f\"{CFG_good.model.replace('/', '-')}_fold{fold}_best.pth\"),\n",
    "                       map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(state['model'])\n",
    "    prediction = inference_fn(test_loader_good, model, device)\n",
    "    predictions_good.append(prediction)\n",
    "    del model, state, prediction; gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "predictions_good = np.mean(predictions_good, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f56d330c-df7f-4f54-8ff3-8293ac943057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173b1c52dc194a31846c83da04fcf850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecbf5264565d4745a8f8c9d5c4d4b7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541d4e3361d64eab8756dc0c5f65c3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517705d78cd4492a9cffd7707668b26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bcff58270a84bcd8756b02973c3dc83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_good = []\n",
    "for fold in CFG_good.trn_fold:\n",
    "    model = CustomModel(CFG_good, config_path=CFG_good.config_path, pretrained=False)\n",
    "    state = torch.load(os.path.join(CFG_good.path, f\"{CFG_good.model.replace('/', '-')}_fold{fold}_best.pth\"),\n",
    "                       map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(state['model'])\n",
    "    prediction = inference_fn(unsup_loader_good, model, device)\n",
    "    predictions_good.append(prediction)\n",
    "    del model, state, prediction; gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "predictions_good = np.mean(predictions_good, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d47d15a-d6ad-4623-b417-13840b6264f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c14965d62f442489efd054a7b287c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891c11d85eb74bf8bea687898213f552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7654c985d04447af4f8ee2989c727a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf2a59746d140c6836133d71aed3953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc92468d7e194dbe819fda5b1e885413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_brand = []\n",
    "for fold in CFG_brand.trn_fold:\n",
    "    model = CustomModel(CFG_brand, config_path=CFG_brand.config_path, pretrained=False)\n",
    "    state = torch.load(os.path.join(CFG_brand.path, f\"{CFG_brand.model.replace('/', '-')}_fold{fold}_best.pth\"),\n",
    "                       map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(state['model'])\n",
    "    prediction = inference_fn(test_loader_brand, model, device)\n",
    "    predictions_brand.append(prediction)\n",
    "    del model, state, prediction; gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "predictions_brand = np.mean(predictions_brand, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9ad7ce5-43de-47a3-bf25-4aef1d6951b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828d272ac33149d39da6a71ce980041c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7564c30fbb44486b841dcd04eb4bb0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a1ed1cdaf744eeb4e2b0c8fab8c0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96c469250ee4291ab214e18b7e70aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf3200b4e544f1aaa61ca397c7e0ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_brand = []\n",
    "for fold in CFG_brand.trn_fold:\n",
    "    model = CustomModel(CFG_brand, config_path=CFG_brand.config_path, pretrained=False)\n",
    "    state = torch.load(os.path.join(CFG_brand.path, f\"{CFG_brand.model.replace('/', '-')}_fold{fold}_best.pth\"),\n",
    "                       map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(state['model'])\n",
    "    prediction = inference_fn(unsup_loader_brand, model, device)\n",
    "    predictions_brand.append(prediction)\n",
    "    del model, state, prediction; gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "predictions_brand = np.mean(predictions_brand, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3acacfc9-8c4e-4f8d-9144-40141ab4c835",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = test['name'].values\n",
    "\n",
    "pred_goods = probs2str_good(predictions_good, test_texts)\n",
    "pred_brands = probs2str_brand(predictions_brand, test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e48e4a20-fed5-4c09-93b4-1b6405848d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsup_texts = unsup['name'].values\n",
    "\n",
    "pred_goods = probs2str_good(predictions_good, unsup_texts)\n",
    "pred_brands = probs2str_brand(predictions_brand, unsup_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7a0f8d9-c58f-4b2c-8f51-69c112e15097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>good</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>зубная щетка орал би три эффект деликатное отб...</td>\n",
       "      <td>зубная щетка</td>\n",
       "      <td>орал би</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>салфетки vister влажные для ко</td>\n",
       "      <td>салфетки</td>\n",
       "      <td>vister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>платье женское dr8517k 7л8999 светло-серый 449...</td>\n",
       "      <td>платье</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>лакомство \"деревенские лакомства\" д/собак мини...</td>\n",
       "      <td>лакомство</td>\n",
       "      <td>деревенские лакомства</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>суппорт гитарный ergo play troster</td>\n",
       "      <td>суппорт</td>\n",
       "      <td>ergo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>999995</td>\n",
       "      <td>f-2296  спонж д/макияжа фигурный (шт)</td>\n",
       "      <td>спонж</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>999996</td>\n",
       "      <td>4 5702737510597 69.88 дифф/arom/1601</td>\n",
       "      <td></td>\n",
       "      <td>arom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>999997</td>\n",
       "      <td>матрас надувной 540*74см tropical bird запл.д/...</td>\n",
       "      <td>матрас</td>\n",
       "      <td>tropical bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>999998</td>\n",
       "      <td>пододеяльник стм страйп 3-сп, размер: 796х185с...</td>\n",
       "      <td>пододеяльник</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>999999</td>\n",
       "      <td>пакет ламинированный вертикальный ?чудесных мг...</td>\n",
       "      <td>пакет</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               name          good                  brand\n",
       "0            0  зубная щетка орал би три эффект деликатное отб...  зубная щетка                орал би\n",
       "1            1                     салфетки vister влажные для ко      салфетки                 vister\n",
       "2            2  платье женское dr8517k 7л8999 светло-серый 449...        платье                       \n",
       "3            3  лакомство \"деревенские лакомства\" д/собак мини...     лакомство  деревенские лакомства\n",
       "4            4                 суппорт гитарный ergo play troster       суппорт                   ergo\n",
       "...        ...                                                ...           ...                    ...\n",
       "999995  999995              f-2296  спонж д/макияжа фигурный (шт)         спонж                       \n",
       "999996  999996               4 5702737510597 69.88 дифф/arom/1601                                 arom\n",
       "999997  999997  матрас надувной 540*74см tropical bird запл.д/...        матрас          tropical bird\n",
       "999998  999998  пододеяльник стм страйп 3-сп, размер: 796х185с...  пододеяльник                       \n",
       "999999  999999  пакет ламинированный вертикальный ?чудесных мг...         пакет                       \n",
       "\n",
       "[1000000 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsup[\"good\"] = pred_goods\n",
    "unsup[\"brand\"] = pred_brands\n",
    "unsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67899d4c-1015-4925-bcce-95cf5349eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsup.to_csv(\"unsup_pred_rubert.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40a89c1e-ed99-4923-959d-82daf93774c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>good</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>клей</td>\n",
       "      <td>ермак</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>торт</td>\n",
       "      <td>сладушка</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>смеситель</td>\n",
       "      <td>calorie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>лимон</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>коньяк</td>\n",
       "      <td>сараджишвили</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4995</td>\n",
       "      <td>рамка</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4996</td>\n",
       "      <td>напиток</td>\n",
       "      <td>red bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4997</td>\n",
       "      <td>наконечники</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4998</td>\n",
       "      <td>шоколад</td>\n",
       "      <td>риттерспорт</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4999</td>\n",
       "      <td>опора</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         good         brand\n",
       "0        0         клей         ермак\n",
       "1        1         торт      сладушка\n",
       "2        2    смеситель       calorie\n",
       "3        3        лимон              \n",
       "4        4       коньяк  сараджишвили\n",
       "...    ...          ...           ...\n",
       "4995  4995        рамка              \n",
       "4996  4996      напиток      red bull\n",
       "4997  4997  наконечники              \n",
       "4998  4998      шоколад   риттерспорт\n",
       "4999  4999        опора              \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[\"good\"] = pred_goods\n",
    "submission[\"brand\"] = pred_brands\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "136bac58-c7e1-4caf-a6b2-abebc60e6188",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"NER_baseline_labse_v4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d916975-83b1-4dd0-9f6d-fabd857f81b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

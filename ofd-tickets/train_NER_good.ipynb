{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213f2d9a-3250-4c88-a659-b9ca5e17b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OUTPUT_DIR = './labse_v4_good'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b71e000a-7f00-4616-b32c-a20739ee02dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    apex=True\n",
    "    print_freq=100\n",
    "    num_workers=10\n",
    "    model=\"sentence-transformers/LaBSE\"\n",
    "    scheduler='linear' # ['linear', 'cosine']\n",
    "    batch_scheduler=True\n",
    "    num_cycles=0.5\n",
    "    num_warmup_steps=0\n",
    "    epochs=10\n",
    "    encoder_lr=2e-5\n",
    "    decoder_lr=2e-5\n",
    "    min_lr=1e-6\n",
    "    eps=1e-6\n",
    "    betas=(0.9, 0.999)\n",
    "    batch_size=256\n",
    "    fc_dropout=0.1\n",
    "    max_len=512\n",
    "    weight_decay=0.01\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    seed=42\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "    train=True\n",
    "    extra=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "248d9e62-7d84-45a2-bd20-3a9a865d9a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizers.__version__: 0.13.3\n",
      "transformers.__version__: 4.30.1\n",
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "import warnings\n",
    "import ast\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import tokenizers\n",
    "import transformers\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "# %env CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a0fa61-0c8d-4f10-82a0-393bf37d9ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(filename=os.path.join(OUTPUT_DIR, \"train\")):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f179e27-68c7-4540-ae2e-0885cb2b92a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def probs2str(results, texts): # (4501, 70, 3)\n",
    "    predictions = []\n",
    "    classes = np.argmax(results, axis=-1)\n",
    "    input_ids_list = [tokenizer(text, \n",
    "                           add_special_tokens=True,\n",
    "                           max_length=CFG.max_len,\n",
    "                           padding=\"max_length\",\n",
    "                           return_offsets_mapping=False)[\"input_ids\"] for text in texts]\n",
    "\n",
    "    for clas, input_ids in zip(classes, input_ids_list):\n",
    "        entities = convert_ids_to_entities(clas, input_ids)\n",
    "\n",
    "        entities = list(itertools.chain(*entities))\n",
    "        prediction = tokenizer.decode(entities, skip_special_tokens=True)\n",
    "        prediction = re.sub(\" - \", \"-\", prediction)\n",
    "        prediction = re.sub(\" & \", \"&\", prediction)\n",
    "        prediction = re.sub(\"##\", \"\", prediction)\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def get_score_f1(y_true, y_pred):\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    acc = 0\n",
    "    # print(y_pred)\n",
    "    for tr, pr in zip(y_true, y_pred):\n",
    "        if tr == pr: acc += 1\n",
    "        pr = frozenset([pr])\n",
    "        tr = frozenset([tr])\n",
    "\n",
    "        tp += len(pr & tr)\n",
    "        fp += len(pr - tr)\n",
    "        fn += len(tr - pr)\n",
    "\n",
    "    if tp == 0:\n",
    "        return 0.0\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    \n",
    "    print(f\"Accuracy: {acc / len(y_true)}\")\n",
    "    score = 2 / (1 / precision + 1 / recall)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01f9a2e4-37f5-4924-adbf-8bf3bec9b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ids_to_entities(ids, tokens=None, o_id=0, b_id=1, i_id=2):\n",
    "    entities = []\n",
    "    entity = []\n",
    "    is_entity_started = False\n",
    "    for index, token in enumerate(ids):\n",
    "        if not is_entity_started and token == b_id:\n",
    "            is_entity_started = True\n",
    "            entity.append(index)\n",
    "        elif is_entity_started and token == i_id:\n",
    "            entity.append(index)\n",
    "    \n",
    "        if (is_entity_started and token == o_id) or (index == (len(ids) - 1)):\n",
    "            is_entity_started = False\n",
    "            entities.append(entity)\n",
    "            entity = []\n",
    "                \n",
    "    if tokens is not None:\n",
    "        tokens = np.array(tokens)\n",
    "        token_entities = []\n",
    "        for entity in entities:\n",
    "            entity = np.array(entity)\n",
    "            if len(entity) > 0:\n",
    "                token_entity = tokens[entity]\n",
    "                token_entities.append(token_entity.tolist())\n",
    "            \n",
    "        return token_entities\n",
    "            \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6855c852-1a17-4536-b118-2df1ffbb8e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    # text = re.sub(\"_\", \" \", text)\n",
    "    # text = re.sub(\"\\d{5,}\", \" \", text) # убираю длиньше чем есть в метках\n",
    "    # text = re.sub(\"\\d+[\\.\\,]?\\d* *(см|гр|г|л|мл|кг|шт|мкм|м)\", \" \", text) # убираю единицы измерения\n",
    "    # text = re.sub(\"\\d+[\\.\\,]?\\d*\\s?%\", \" \", text) # процентное содержание в товарах\n",
    "    # text = re.sub(\"\\[.*\\]\", \" \", text) # убираем скобки и содержимое\n",
    "    # text = re.sub(\"<.+>\", \" \", text) # убираем скобки и содержимое\n",
    "    # text = re.sub(\"{.+}\", \" \", text) # убираем скобки и содержимое\n",
    "    # for el in [\"\\x07\", \"\\t\", \"\\n\", \"\\x18\", \"\\x1a\", '\"', \",\", \"/\", \":\", \";\", '\\\\\\\\', '\\|', '~', \"\\x7f\", \"\\xa0\", \"°\", \"·\", \"є\", \"∙\", \"╣\"]:\n",
    "    #     text = re.sub(el, \" \", text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "def get_good_pos(row):\n",
    "    if row[\"good\"] == \"\": return (0, 0)\n",
    "    start = row[\"name\"].lower().find(row[\"good\"])\n",
    "    if start == -1:\n",
    "        end = -1\n",
    "    else:\n",
    "        end = start + len(row[\"good\"])\n",
    "\n",
    "    return (start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17845f45-e708-4da2-a843-4e99852b9846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23412, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>good</th>\n",
       "      <th>good_pos</th>\n",
       "      <th>strat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>petmax бантик леопард с красн розой 2шт</td>\n",
       "      <td>бантик</td>\n",
       "      <td>(7, 13)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87191 бусы для елки шарики_87191</td>\n",
       "      <td>бусы</td>\n",
       "      <td>(6, 10)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>футболка piazza italia wr011446881</td>\n",
       "      <td>футболка</td>\n",
       "      <td>(0, 8)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7) yi572-03x-one заколка для волос для девочки</td>\n",
       "      <td>заколка</td>\n",
       "      <td>(17, 24)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>одежда (вес) 1500</td>\n",
       "      <td>одежда</td>\n",
       "      <td>(0, 6)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             name      good  good_pos  strat\n",
       "0         petmax бантик леопард с красн розой 2шт    бантик   (7, 13)      0\n",
       "1                87191 бусы для елки шарики_87191      бусы   (6, 10)      0\n",
       "2              футболка piazza italia wr011446881  футболка    (0, 8)      0\n",
       "3  7) yi572-03x-one заколка для волос для девочки   заколка  (17, 24)      0\n",
       "4                               одежда (вес) 1500    одежда    (0, 6)      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_supervised_dataset.csv\")\n",
    "df.good = df.good.replace(\"лента.\", \"лента\")\n",
    "df.good = df.good.replace(\"товара нет\", np.nan)\n",
    "df.good = df.good.replace(\"т,а,б,л,е,т,к,и\", \"таблетки\")\n",
    "df.good = df.good.replace('автокормушка\", \"автопоилка', \"автокормушка,автопоилка\")\n",
    "\n",
    "df = df[[\"name\", \"good\"]].fillna(\"\")\n",
    "df.name = df.name.apply(preprocess_text)\n",
    "df[\"good_pos\"] = df.apply(get_good_pos, axis=1)\n",
    "df = df[df.good_pos != (-1,-1)].reset_index(drop=True)\n",
    "\n",
    "df[\"strat\"] = df.good_pos.apply(lambda x: 1 if x == (0, 0) else 0)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a116e0db-1905-4d74-bb10-f58959c8f5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    4683\n",
       "1    4683\n",
       "2    4682\n",
       "3    4682\n",
       "4    4682\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Fold = StratifiedKFold(n_splits=CFG.n_fold)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(df, df.strat.values)):\n",
    "    df.loc[val_index, 'fold'] = int(n)\n",
    "df['fold'] = df['fold'].astype(int)\n",
    "display(df.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7b28df1-b98f-4069-aa7c-7c261f834bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.extra:\n",
    "    extra_data = pd.read_csv(\"unsup_pred_rubert.csv\")\n",
    "    extra_data = extra_data[[\"name\", \"good\"]].fillna(\"\")\n",
    "    extra_data.name = extra_data.name.apply(preprocess_text)\n",
    "    extra_data[\"good_pos\"] = extra_data.apply(get_good_pos, axis=1)\n",
    "    extra_data = extra_data[extra_data.good_pos != (-1,-1)].reset_index(drop=True)\n",
    "    extra_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1b4c29b-a5fc-44cd-813f-d4cb980650c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# tokenizer\n",
    "# ====================================================\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
    "tokenizer.save_pretrained(os.path.join(OUTPUT_DIR, \"tokenizer\"))\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "646a107d-db84-4d89-955e-f14e797563ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd738f7194ce402484603e35df0d02df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23412 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_len: 66\n"
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "tk0 = tqdm(df.name.values, total=len(df))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "    lengths.append(length)\n",
    "\n",
    "if CFG.extra:\n",
    "    tk1 = tqdm(extra_data.name.values, total=len(extra_data))\n",
    "    for text in tk1:\n",
    "        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "        lengths.append(length)\n",
    "\n",
    "CFG.max_len = max(lengths) + 2 # cls & sep\n",
    "LOGGER.info(f\"max_len: {CFG.max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4b282dc-a8fc-4158-93cf-885b7e9351f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(cfg, text):\n",
    "    inputs = cfg.tokenizer(text, \n",
    "                           add_special_tokens=True,\n",
    "                           max_length=CFG.max_len,\n",
    "                           padding=\"max_length\",\n",
    "                           return_offsets_mapping=False)\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def create_label(cfg, text, annotation, pos):\n",
    "    # \"O\" -> 0\n",
    "    # \"B\" -> 1\n",
    "    # \"I\" -> 2\n",
    "    encoded = cfg.tokenizer(text,\n",
    "                            add_special_tokens=True,\n",
    "                            max_length=CFG.max_len,\n",
    "                            padding=\"max_length\",\n",
    "                            return_offsets_mapping=True)\n",
    "    offset_mapping = encoded['offset_mapping']\n",
    "    ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n",
    "    label = np.zeros(len(offset_mapping))\n",
    "    label[ignore_idxes] = -1\n",
    "\n",
    "    if pos == (0, 0):\n",
    "        return torch.tensor(label, dtype=torch.long)\n",
    "    for i in range(len(offset_mapping)):\n",
    "        if offset_mapping[i] == (0, 0):\n",
    "            continue\n",
    "        elif offset_mapping[i][0] == pos[0]:\n",
    "            label[i] = 1\n",
    "        elif offset_mapping[i][1] <= pos[1] and offset_mapping[i][0] >= pos[0]:\n",
    "            label[i] = 2\n",
    "\n",
    "    return torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.name = df['name'].values\n",
    "        self.good = df['good'].values\n",
    "        self.good_pos = df['good_pos'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.name)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, \n",
    "                               self.name[item])\n",
    "        label = create_label(self.cfg, \n",
    "                             self.name[item], \n",
    "                             self.good[item], \n",
    "                             self.good_pos[item])\n",
    "        return inputs, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93b662a4-2fdb-4814-9c73-ec5ea0ab37b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel(self.config)\n",
    "        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 3)\n",
    "        self._init_weights(self.fc)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        return last_hidden_states\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(self.fc_dropout(feature))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f62c135b-df76-41f1-a542-3a74b29b3d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86d2b687-f9f6-40e1-a2e2-fb34914bd42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    global_step = 0\n",
    "    for step, (inputs, labels) in enumerate(train_loader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            y_preds = model(inputs)\n",
    "        loss = criterion(y_preds.transpose(1, 2), labels)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch+1, step, len(train_loader), \n",
    "                          remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                          loss=losses,\n",
    "                          grad_norm=grad_norm,\n",
    "                          lr=scheduler.get_lr()[0]))\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d838e9a-1648-41e3-86cd-0082807e5e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (inputs, labels) in enumerate(valid_loader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        loss = criterion(y_preds.transpose(1, 2), labels)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(y_preds.softmax(-1).to('cpu').numpy()) ####\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, len(valid_loader),\n",
    "                          loss=losses,\n",
    "                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "412952ad-5b7e-46dd-855f-57e9cbbffe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(folds, fold):\n",
    "    \n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n",
    "\n",
    "    if CFG.extra:\n",
    "        train_folds = pd.concat([train_folds, extra_data], axis=0)\n",
    "    \n",
    "    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n",
    "    valid_texts = valid_folds['name'].values\n",
    "    valid_labels = valid_folds['good'].values\n",
    "    \n",
    "    train_dataset = TrainDataset(CFG, train_folds)\n",
    "    valid_dataset = TrainDataset(CFG, valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = CustomModel(CFG, config_path=None, pretrained=True)\n",
    "    torch.save(model.config, os.path.join(OUTPUT_DIR, \"config.pth\"))\n",
    "    model.to(device)\n",
    "    \n",
    "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "             'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "\n",
    "    optimizer_parameters = get_optimizer_params(model,\n",
    "                                                encoder_lr=CFG.encoder_lr, \n",
    "                                                decoder_lr=CFG.decoder_lr,\n",
    "                                                weight_decay=CFG.weight_decay)\n",
    "    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n",
    "    \n",
    "    # ====================================================\n",
    "    # scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "        if cfg.scheduler=='linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif cfg.scheduler=='cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
    "            )\n",
    "        return scheduler\n",
    "    \n",
    "    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n",
    "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "    \n",
    "    best_score = 0.0\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n",
    "        # scoring\n",
    "        preds = probs2str(predictions, valid_texts)\n",
    "        score = get_score_f1(valid_labels, preds)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n",
    "        \n",
    "        if best_score < score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'predictions': np.argmax(predictions, axis=-1)},\n",
    "                        os.path.join(OUTPUT_DIR, f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\"))\n",
    "\n",
    "    predictions = torch.load(os.path.join(OUTPUT_DIR, f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\"), \n",
    "                             map_location=torch.device('cpu'))['predictions']\n",
    "    valid_folds[[i for i in range(CFG.max_len)]] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ac07b17-a16c-474f-89d1-f8e87b0d46ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/73] Elapsed 0m 0s (remain 1m 7s) Loss: 1.0244(1.0244) Grad: nan  LR: 0.00001997  \n",
      "Epoch: [1][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0505(0.2408) Grad: 6431.5391  LR: 0.00001800  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0545(0.0545) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.1391(0.0422) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.2408  avg_val_loss: 0.0422  time: 23s\n",
      "Epoch 1 - Score: 0.9216\n",
      "Epoch 1 - Save Best Score: 0.9216 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9216314328421952\n",
      "Epoch: [2][0/73] Elapsed 0m 0s (remain 0m 30s) Loss: 0.0386(0.0386) Grad: nan  LR: 0.00001798  \n",
      "Epoch: [2][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0405(0.0420) Grad: 10838.8818  LR: 0.00001601  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0504(0.0504) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.1165(0.0347) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.0420  avg_val_loss: 0.0347  time: 23s\n",
      "Epoch 2 - Score: 0.9357\n",
      "Epoch 2 - Save Best Score: 0.9357 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9357249626307922\n",
      "Epoch: [3][0/73] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0276(0.0276) Grad: nan  LR: 0.00001598  \n",
      "Epoch: [3][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0316(0.0321) Grad: 10996.6025  LR: 0.00001401  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0502(0.0502) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.1411(0.0349) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.0321  avg_val_loss: 0.0349  time: 23s\n",
      "Epoch 3 - Score: 0.9430\n",
      "Epoch 3 - Save Best Score: 0.9430 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.942985265855221\n",
      "Epoch: [4][0/73] Elapsed 0m 0s (remain 0m 30s) Loss: 0.0311(0.0311) Grad: nan  LR: 0.00001398  \n",
      "Epoch: [4][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0295(0.0269) Grad: 14206.8525  LR: 0.00001201  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0500(0.0500) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.1300(0.0333) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.0269  avg_val_loss: 0.0333  time: 23s\n",
      "Epoch 4 - Score: 0.9455\n",
      "Epoch 4 - Save Best Score: 0.9455 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9455477258167841\n",
      "Epoch: [5][0/73] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0221(0.0221) Grad: nan  LR: 0.00001198  \n",
      "Epoch: [5][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0172(0.0237) Grad: nan  LR: 0.00001001  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0540(0.0540) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.1339(0.0338) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.0237  avg_val_loss: 0.0338  time: 23s\n",
      "Epoch 5 - Score: 0.9468\n",
      "Epoch 5 - Save Best Score: 0.9468 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9468289557975657\n",
      "Epoch: [6][0/73] Elapsed 0m 0s (remain 0m 30s) Loss: 0.0237(0.0237) Grad: nan  LR: 0.00000999  \n",
      "Epoch: [6][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0266(0.0214) Grad: 18426.9355  LR: 0.00000802  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0587(0.0587) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.1429(0.0348) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.0214  avg_val_loss: 0.0348  time: 23s\n",
      "Epoch 6 - Score: 0.9462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9461883408071748\n",
      "Epoch: [7][0/73] Elapsed 0m 0s (remain 0m 31s) Loss: 0.0155(0.0155) Grad: nan  LR: 0.00000799  \n",
      "Epoch: [7][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0220(0.0197) Grad: 11151.4600  LR: 0.00000602  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0581(0.0581) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.1502(0.0368) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.0197  avg_val_loss: 0.0368  time: 23s\n",
      "Epoch 7 - Score: 0.9451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9451206491565236\n",
      "Epoch: [8][0/73] Elapsed 0m 0s (remain 0m 30s) Loss: 0.0204(0.0204) Grad: nan  LR: 0.00000599  \n",
      "Epoch: [8][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0181(0.0181) Grad: 12376.8428  LR: 0.00000402  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0611(0.0611) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.1454(0.0363) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.0181  avg_val_loss: 0.0363  time: 23s\n",
      "Epoch 8 - Score: 0.9485\n",
      "Epoch 8 - Save Best Score: 0.9485 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9485372624386077\n",
      "Epoch: [9][0/73] Elapsed 0m 0s (remain 0m 30s) Loss: 0.0114(0.0114) Grad: nan  LR: 0.00000399  \n",
      "Epoch: [9][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0118(0.0170) Grad: 9837.9834  LR: 0.00000202  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0616(0.0616) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.1452(0.0366) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.0170  avg_val_loss: 0.0366  time: 23s\n",
      "Epoch 9 - Score: 0.9485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9485372624386077\n",
      "Epoch: [10][0/73] Elapsed 0m 0s (remain 0m 30s) Loss: 0.0122(0.0122) Grad: nan  LR: 0.00000200  \n",
      "Epoch: [10][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0215(0.0164) Grad: 11072.4062  LR: 0.00000003  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0610(0.0610) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.1455(0.0366) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.0164  avg_val_loss: 0.0366  time: 23s\n",
      "Epoch 10 - Score: 0.9483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9483237241084774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 result ==========\n",
      "Score: 0.9485\n",
      "========== fold: 1 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9485372624386077\n",
      "Epoch: [1][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 1.1738(1.1738) Grad: nan  LR: 0.00001997  \n",
      "Epoch: [1][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0450(0.2535) Grad: 7033.1733  LR: 0.00001800  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0397(0.0397) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0162(0.0450) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.2535  avg_val_loss: 0.0450  time: 23s\n",
      "Epoch 1 - Score: 0.9174\n",
      "Epoch 1 - Save Best Score: 0.9174 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91736066623959\n",
      "Epoch: [2][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0359(0.0359) Grad: nan  LR: 0.00001798  \n",
      "Epoch: [2][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0349(0.0407) Grad: 11070.4512  LR: 0.00001601  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0362(0.0362) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0121(0.0361) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.0407  avg_val_loss: 0.0361  time: 23s\n",
      "Epoch 2 - Score: 0.9327\n",
      "Epoch 2 - Save Best Score: 0.9327 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9327354260089686\n",
      "Epoch: [3][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0363(0.0363) Grad: nan  LR: 0.00001598  \n",
      "Epoch: [3][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0458(0.0326) Grad: 21227.8984  LR: 0.00001401  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0345(0.0345) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0144(0.0358) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.0326  avg_val_loss: 0.0358  time: 23s\n",
      "Epoch 3 - Score: 0.9362\n",
      "Epoch 3 - Save Best Score: 0.9362 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9361520392910527\n",
      "Epoch: [4][0/73] Elapsed 0m 0s (remain 0m 34s) Loss: 0.0239(0.0239) Grad: nan  LR: 0.00001398  \n",
      "Epoch: [4][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0256(0.0273) Grad: 12708.5273  LR: 0.00001201  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0336(0.0336) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0141(0.0331) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.0273  avg_val_loss: 0.0331  time: 23s\n",
      "Epoch 4 - Score: 0.9387\n",
      "Epoch 4 - Save Best Score: 0.9387 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9387144992526159\n",
      "Epoch: [5][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0170(0.0170) Grad: nan  LR: 0.00001198  \n",
      "Epoch: [5][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0260(0.0240) Grad: 10664.3125  LR: 0.00001001  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0318(0.0318) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0126(0.0326) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.0240  avg_val_loss: 0.0326  time: 23s\n",
      "Epoch 5 - Score: 0.9421\n",
      "Epoch 5 - Save Best Score: 0.9421 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9421311125346999\n",
      "Epoch: [6][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0204(0.0204) Grad: nan  LR: 0.00000999  \n",
      "Epoch: [6][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0157(0.0212) Grad: 12257.4707  LR: 0.00000802  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0310(0.0310) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0115(0.0330) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.0212  avg_val_loss: 0.0330  time: 23s\n",
      "Epoch 6 - Score: 0.9419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9419175742045697\n",
      "Epoch: [7][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0118(0.0118) Grad: nan  LR: 0.00000799  \n",
      "Epoch: [7][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0177(0.0191) Grad: 10462.3486  LR: 0.00000602  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0332(0.0332) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0122(0.0333) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.0191  avg_val_loss: 0.0333  time: 23s\n",
      "Epoch 7 - Score: 0.9447\n",
      "Epoch 7 - Save Best Score: 0.9447 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9446935724962631\n",
      "Epoch: [8][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0158(0.0158) Grad: nan  LR: 0.00000599  \n",
      "Epoch: [8][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0199(0.0176) Grad: 9720.4922  LR: 0.00000402  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0320(0.0320) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0134(0.0349) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.0176  avg_val_loss: 0.0349  time: 23s\n",
      "Epoch 8 - Score: 0.9423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9423446508648302\n",
      "Epoch: [9][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0116(0.0116) Grad: nan  LR: 0.00000399  \n",
      "Epoch: [9][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0219(0.0169) Grad: 18970.9512  LR: 0.00000202  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0327(0.0327) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0131(0.0344) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.0169  avg_val_loss: 0.0344  time: 23s\n",
      "Epoch 9 - Score: 0.9430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.942985265855221\n",
      "Epoch: [10][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0188(0.0188) Grad: nan  LR: 0.00000200  \n",
      "Epoch: [10][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0127(0.0158) Grad: 9053.9492  LR: 0.00000003  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0325(0.0325) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0133(0.0345) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.0158  avg_val_loss: 0.0345  time: 23s\n",
      "Epoch 10 - Score: 0.9438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9438394191757421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 1 result ==========\n",
      "Score: 0.9447\n",
      "========== fold: 2 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9446935724962631\n",
      "Epoch: [1][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 1.1650(1.1650) Grad: nan  LR: 0.00001997  \n",
      "Epoch: [1][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0494(0.2402) Grad: 7348.7065  LR: 0.00001800  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0504(0.0504) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0487(0.0444) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.2402  avg_val_loss: 0.0444  time: 23s\n",
      "Epoch 1 - Score: 0.9133\n",
      "Epoch 1 - Save Best Score: 0.9133 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9132849209739428\n",
      "Epoch: [2][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0374(0.0374) Grad: nan  LR: 0.00001798  \n",
      "Epoch: [2][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0424(0.0401) Grad: 11263.0615  LR: 0.00001601  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0440(0.0440) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0340(0.0372) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.0401  avg_val_loss: 0.0372  time: 23s\n",
      "Epoch 2 - Score: 0.9289\n",
      "Epoch 2 - Save Best Score: 0.9289 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.928876548483554\n",
      "Epoch: [3][0/73] Elapsed 0m 0s (remain 0m 33s) Loss: 0.0352(0.0352) Grad: nan  LR: 0.00001598  \n",
      "Epoch: [3][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0457(0.0318) Grad: 11298.7227  LR: 0.00001401  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0407(0.0407) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0310(0.0335) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.0318  avg_val_loss: 0.0335  time: 23s\n",
      "Epoch 3 - Score: 0.9361\n",
      "Epoch 3 - Save Best Score: 0.9361 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9361384023921401\n",
      "Epoch: [4][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0346(0.0346) Grad: nan  LR: 0.00001398  \n",
      "Epoch: [4][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0282(0.0264) Grad: 10485.3125  LR: 0.00001201  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0428(0.0428) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0313(0.0343) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.0264  avg_val_loss: 0.0343  time: 23s\n",
      "Epoch 4 - Score: 0.9370\n",
      "Epoch 4 - Save Best Score: 0.9370 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9369927381460914\n",
      "Epoch: [5][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0210(0.0210) Grad: nan  LR: 0.00001198  \n",
      "Epoch: [5][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0274(0.0232) Grad: 10959.9199  LR: 0.00001001  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0411(0.0411) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0286(0.0324) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.0232  avg_val_loss: 0.0324  time: 23s\n",
      "Epoch 5 - Score: 0.9389\n",
      "Epoch 5 - Save Best Score: 0.9389 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9389149935924819\n",
      "Epoch: [6][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0304(0.0304) Grad: nan  LR: 0.00000999  \n",
      "Epoch: [6][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0119(0.0209) Grad: 9916.3828  LR: 0.00000802  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0405(0.0405) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0291(0.0326) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.0209  avg_val_loss: 0.0326  time: 23s\n",
      "Epoch 6 - Score: 0.9417\n",
      "Epoch 6 - Save Best Score: 0.9417 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9416915847928236\n",
      "Epoch: [7][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0175(0.0175) Grad: nan  LR: 0.00000799  \n",
      "Epoch: [7][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0241(0.0187) Grad: 12999.5771  LR: 0.00000602  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0417(0.0417) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0260(0.0335) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.0187  avg_val_loss: 0.0335  time: 23s\n",
      "Epoch 7 - Score: 0.9436\n",
      "Epoch 7 - Save Best Score: 0.9436 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.943613840239214\n",
      "Epoch: [8][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0162(0.0162) Grad: nan  LR: 0.00000599  \n",
      "Epoch: [8][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0164(0.0176) Grad: 12011.6494  LR: 0.00000402  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0437(0.0437) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0269(0.0332) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.0176  avg_val_loss: 0.0332  time: 23s\n",
      "Epoch 8 - Score: 0.9451\n",
      "Epoch 8 - Save Best Score: 0.9451 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9451089278086288\n",
      "Epoch: [9][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0178(0.0178) Grad: nan  LR: 0.00000399  \n",
      "Epoch: [9][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0084(0.0162) Grad: 8920.5215  LR: 0.00000202  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0444(0.0444) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0256(0.0338) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.0162  avg_val_loss: 0.0338  time: 23s\n",
      "Epoch 9 - Score: 0.9455\n",
      "Epoch 9 - Save Best Score: 0.9455 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9455360956856045\n",
      "Epoch: [10][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0141(0.0141) Grad: nan  LR: 0.00000200  \n",
      "Epoch: [10][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0071(0.0156) Grad: 6704.8804  LR: 0.00000003  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0444(0.0444) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0255(0.0337) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.0156  avg_val_loss: 0.0337  time: 23s\n",
      "Epoch 10 - Score: 0.9445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9444681759931653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 2 result ==========\n",
      "Score: 0.9455\n",
      "========== fold: 3 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9455360956856045\n",
      "Epoch: [1][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.9561(0.9561) Grad: nan  LR: 0.00001997  \n",
      "Epoch: [1][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0450(0.2282) Grad: 7400.3936  LR: 0.00001800  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0332(0.0332) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0419(0.0466) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.2282  avg_val_loss: 0.0466  time: 23s\n",
      "Epoch 1 - Score: 0.9090\n",
      "Epoch 1 - Save Best Score: 0.9090 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9090132422041862\n",
      "Epoch: [2][0/73] Elapsed 0m 0s (remain 0m 33s) Loss: 0.0386(0.0386) Grad: nan  LR: 0.00001798  \n",
      "Epoch: [2][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0350(0.0403) Grad: 13203.0801  LR: 0.00001601  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0271(0.0271) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0352(0.0394) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.0403  avg_val_loss: 0.0394  time: 23s\n",
      "Epoch 2 - Score: 0.9238\n",
      "Epoch 2 - Save Best Score: 0.9238 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9237505339598462\n",
      "Epoch: [3][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0334(0.0334) Grad: nan  LR: 0.00001598  \n",
      "Epoch: [3][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0453(0.0318) Grad: 14637.5000  LR: 0.00001401  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0249(0.0249) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0327(0.0363) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.0318  avg_val_loss: 0.0363  time: 23s\n",
      "Epoch 3 - Score: 0.9327\n",
      "Epoch 3 - Save Best Score: 0.9327 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9327210593763349\n",
      "Epoch: [4][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0317(0.0317) Grad: nan  LR: 0.00001398  \n",
      "Epoch: [4][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0309(0.0270) Grad: 12522.8916  LR: 0.00001201  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0228(0.0228) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0344(0.0335) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.0270  avg_val_loss: 0.0335  time: 23s\n",
      "Epoch 4 - Score: 0.9376\n",
      "Epoch 4 - Save Best Score: 0.9376 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9376334899615549\n",
      "Epoch: [5][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0213(0.0213) Grad: nan  LR: 0.00001198  \n",
      "Epoch: [5][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0327(0.0228) Grad: 10184.6074  LR: 0.00001001  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0239(0.0239) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0356(0.0339) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.0228  avg_val_loss: 0.0339  time: 23s\n",
      "Epoch 5 - Score: 0.9391\n",
      "Epoch 5 - Save Best Score: 0.9391 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9391285775309697\n",
      "Epoch: [6][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0254(0.0254) Grad: nan  LR: 0.00000999  \n",
      "Epoch: [6][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0170(0.0211) Grad: 12499.0176  LR: 0.00000802  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0232(0.0232) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0352(0.0351) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.0211  avg_val_loss: 0.0351  time: 23s\n",
      "Epoch 6 - Score: 0.9376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9376334899615549\n",
      "Epoch: [7][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0241(0.0241) Grad: nan  LR: 0.00000799  \n",
      "Epoch: [7][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0117(0.0191) Grad: 8141.4263  LR: 0.00000602  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0225(0.0225) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0323(0.0341) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.0191  avg_val_loss: 0.0341  time: 23s\n",
      "Epoch 7 - Score: 0.9415\n",
      "Epoch 7 - Save Best Score: 0.9415 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9414780008543358\n",
      "Epoch: [8][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0220(0.0220) Grad: nan  LR: 0.00000599  \n",
      "Epoch: [8][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0163(0.0175) Grad: 14190.3916  LR: 0.00000402  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0224(0.0224) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0348(0.0357) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.0175  avg_val_loss: 0.0357  time: 23s\n",
      "Epoch 8 - Score: 0.9423\n",
      "Epoch 8 - Save Best Score: 0.9423 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9423323366082871\n",
      "Epoch: [9][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0100(0.0100) Grad: nan  LR: 0.00000399  \n",
      "Epoch: [9][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0090(0.0164) Grad: 7524.8320  LR: 0.00000202  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0223(0.0223) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0333(0.0356) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.0164  avg_val_loss: 0.0356  time: 23s\n",
      "Epoch 9 - Score: 0.9421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9421187526697993\n",
      "Epoch: [10][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0097(0.0097) Grad: nan  LR: 0.00000200  \n",
      "Epoch: [10][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0121(0.0155) Grad: 8140.7256  LR: 0.00000003  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0220(0.0220) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0328(0.0358) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.0155  avg_val_loss: 0.0358  time: 23s\n",
      "Epoch 10 - Score: 0.9419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9419051687313114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 3 result ==========\n",
      "Score: 0.9423\n",
      "========== fold: 4 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9423323366082871\n",
      "Epoch: [1][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 1.2236(1.2236) Grad: nan  LR: 0.00001997  \n",
      "Epoch: [1][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0392(0.2476) Grad: 6126.8633  LR: 0.00001800  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0634(0.0634) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0388(0.0453) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.2476  avg_val_loss: 0.0453  time: 23s\n",
      "Epoch 1 - Score: 0.9090\n",
      "Epoch 1 - Save Best Score: 0.9090 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9090132422041862\n",
      "Epoch: [2][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0404(0.0404) Grad: nan  LR: 0.00001798  \n",
      "Epoch: [2][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0506(0.0409) Grad: 14775.3203  LR: 0.00001601  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0461(0.0461) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0321(0.0372) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.0409  avg_val_loss: 0.0372  time: 23s\n",
      "Epoch 2 - Score: 0.9310\n",
      "Epoch 2 - Save Best Score: 0.9310 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9310123878684323\n",
      "Epoch: [3][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0290(0.0290) Grad: nan  LR: 0.00001598  \n",
      "Epoch: [3][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0219(0.0325) Grad: 9758.8691  LR: 0.00001401  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0419(0.0419) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0325(0.0329) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.0325  avg_val_loss: 0.0329  time: 23s\n",
      "Epoch 3 - Score: 0.9370\n",
      "Epoch 3 - Save Best Score: 0.9370 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9369927381460914\n",
      "Epoch: [4][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0233(0.0233) Grad: nan  LR: 0.00001398  \n",
      "Epoch: [4][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0219(0.0278) Grad: 9229.1758  LR: 0.00001201  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0381(0.0381) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0335(0.0323) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.0278  avg_val_loss: 0.0323  time: 23s\n",
      "Epoch 4 - Score: 0.9378\n",
      "Epoch 4 - Save Best Score: 0.9378 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9378470739000427\n",
      "Epoch: [5][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0119(0.0119) Grad: nan  LR: 0.00001198  \n",
      "Epoch: [5][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0402(0.0241) Grad: 14497.2402  LR: 0.00001001  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0348(0.0348) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0265(0.0307) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.0241  avg_val_loss: 0.0307  time: 23s\n",
      "Epoch 5 - Score: 0.9408\n",
      "Epoch 5 - Save Best Score: 0.9408 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9408372490388722\n",
      "Epoch: [6][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0284(0.0284) Grad: nan  LR: 0.00000999  \n",
      "Epoch: [6][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0239(0.0207) Grad: 10765.4434  LR: 0.00000802  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0337(0.0337) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0291(0.0323) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.0207  avg_val_loss: 0.0323  time: 23s\n",
      "Epoch 6 - Score: 0.9417\n",
      "Epoch 6 - Save Best Score: 0.9417 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9416915847928236\n",
      "Epoch: [7][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0217(0.0217) Grad: nan  LR: 0.00000799  \n",
      "Epoch: [7][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0246(0.0191) Grad: 15332.1729  LR: 0.00000602  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0339(0.0339) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0286(0.0322) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.0191  avg_val_loss: 0.0322  time: 23s\n",
      "Epoch 7 - Score: 0.9411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9410508329773601\n",
      "Epoch: [8][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0191(0.0191) Grad: nan  LR: 0.00000599  \n",
      "Epoch: [8][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0310(0.0180) Grad: 20850.0391  LR: 0.00000402  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0320(0.0320) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0288(0.0327) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.0180  avg_val_loss: 0.0327  time: 23s\n",
      "Epoch 8 - Score: 0.9451\n",
      "Epoch 8 - Save Best Score: 0.9451 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9451089278086288\n",
      "Epoch: [9][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0108(0.0108) Grad: nan  LR: 0.00000399  \n",
      "Epoch: [9][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0267(0.0164) Grad: 13691.5332  LR: 0.00000202  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0324(0.0324) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0287(0.0328) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.0164  avg_val_loss: 0.0328  time: 23s\n",
      "Epoch 9 - Score: 0.9462\n",
      "Epoch 9 - Save Best Score: 0.9462 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9461768475010679\n",
      "Epoch: [10][0/73] Elapsed 0m 0s (remain 0m 32s) Loss: 0.0226(0.0226) Grad: nan  LR: 0.00000200  \n",
      "Epoch: [10][72/73] Elapsed 0m 19s (remain 0m 0s) Loss: 0.0217(0.0157) Grad: 13092.1074  LR: 0.00000003  \n",
      "EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0317(0.0317) \n",
      "EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) Loss: 0.0298(0.0333) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.0157  avg_val_loss: 0.0333  time: 23s\n",
      "Epoch 10 - Score: 0.9455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9455360956856045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 4 result ==========\n",
      "Score: 0.9462\n",
      "========== CV ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9461768475010679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Score: 0.9455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9454553220570647\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    def get_result(oof_df):\n",
    "        predictions = []\n",
    "        classes = oof_df[[i for i in range(CFG.max_len)]].values.tolist()\n",
    "        input_ids_list = [CFG.tokenizer(text, \n",
    "                           add_special_tokens=True,\n",
    "                           max_length=CFG.max_len,\n",
    "                           padding=\"max_length\",\n",
    "                           return_offsets_mapping=False)[\"input_ids\"] for text in oof_df.name.values]\n",
    "        for clas, input_ids in zip(classes, input_ids_list):\n",
    "            entities = convert_ids_to_entities(clas, input_ids)\n",
    "    \n",
    "            entities = list(itertools.chain(*entities))\n",
    "            # entities = tokenizer.convert_ids_to_tokens(entities)\n",
    "            # entities = [entity for entity in entities if entity != \"[PAD]\"]\n",
    "            # prediction = tokenizer.convert_tokens_to_string(entities)\n",
    "            prediction = tokenizer.decode(entities, skip_special_tokens=True)\n",
    "            prediction = re.sub(\" - \", \"-\", prediction)\n",
    "            prediction = re.sub(\" & \", \"&\", prediction)\n",
    "            prediction = re.sub(\"##\", \"\", prediction)\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        score = get_score_f1(oof_df.good.values, predictions)\n",
    "        LOGGER.info(f'Score: {score:<.4f}')\n",
    "    \n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df = train_loop(df, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                get_result(_oof_df)\n",
    "        oof_df = oof_df.reset_index(drop=True)\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "        oof_df.to_pickle(os.path.join(OUTPUT_DIR, \"oof_df.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbae4d6d-a762-48d6-8e15-f6d24323208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9367\n",
    "# 0.9427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3516e80a-47e2-482f-8d2c-5624227f5a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c476c18-25c9-49d2-9ee2-20119ad0a5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111fcf85-b5e9-4172-985b-c3a2a125308a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc264600-ee9b-4ab2-9c19-14d6942cac8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdc1353-7fbb-4086-914e-82c24a3d1636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99de022-dcf2-4cb7-8072-e531c106c918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c04ded-3cf7-4a01-a075-807969084892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f318112-b609-4bc8-b3d7-0d4d34436dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa72970-7f45-4d93-92bf-fc254c5e7268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76a150e-420b-4931-9a3d-1eca5ab9ddd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a2c71d-1226-4254-b890-bcc7b16d5779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e842db-7b79-496a-9618-b4b8f6d0ce64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a6b1ee-9b52-49ae-8075-b61e2125f58d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
